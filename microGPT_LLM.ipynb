{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f9a4f013",
      "metadata": {
        "id": "f9a4f013"
      },
      "source": [
        "# Language Models\n",
        "\n",
        "In our pursuit of making computers understand and generate human-like text, LLM were developed.\n",
        "Language modeling in general is concerned with predicting the next word in a sequence of words. One of the early and basic examples of LMs is the n-gram model, where the probability of a word occurring is calculated based on the previous n-1 words.\n",
        "\n",
        "For example, in a 5-gram model, and the sentence \"The quick brown fox jumps over the lazy dog\", the probability of the word \"dog\" occuring is calculated based on the previous 4 words \"over the lazy\". This is a very simple model and does not capture the context of the sentence very well.\n",
        "\n",
        "<img src=\"https://www.baeldung.com/wp-content/uploads/sites/4/2023/05/Language-Model-N-gram.jpg\" />\n",
        "\n",
        "source: https://www.baeldung.com/cs/large-language-models\n",
        "\n",
        "## Large Language Models\n",
        "The benifit of N-gram models is limited. This is where large language models (LLMs) come in. LLMs are able to capture the context of the sentence and generate more accurate predictions. They language models that use large neural networks with up to billions of parameters. They can capture more complex syntax and semantics of the human language. They can perform a number of tasks, ranging from translation, identifying offensive content, or even passing professional exams.\n",
        "\n",
        "To further understand LLMs, we will introduce two concepts here, **embedding** and **tokenization**.\n",
        "\n",
        "### Embeddings\n",
        "You can think of embeddings as values assigned to words that represent aspects of their meaning. For example, if we want to describe objects in terms of their size and taste, a dog will score high on the size and low on the taste, while a rock will score low on both, and so on. When the model learns such values, it acquires some form of representation of word *meaning*. That is why, **embeddings are a major part of what the models are actually trained on**.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/abdulrahman1123/analysis_examples/refs/heads/main/embeddings.png\" width=400 height=423 />\n",
        "\n",
        "### Tokenization and Encoding\n",
        "Have you ever subscriped to the 'pay as you go' tier in ChatGPT, Cluade or Deepseek? If so, then you probably noticed that they calculate usage by the number of tokens. But what are tokens?\n",
        "Well, they are the smallest chunks that you split your text into. Usually, they represent sub-word syllables. For example, the word \"unbelievable\" can consist of three tokens, \"un\", \"believ\" and \"able\". However, we can determine the granularity of our definition of tokens, and we can split our data on the letter level, or on the whole-word level if we want to.\n",
        "\n",
        "Finally, we all know how computers love numbers. So, we want to convert all words to numbers before feeding them to the model for training. This is known as **encoding**. When we get the output of the machine, we convert it back to words using **decoding**.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/abdulrahman1123/analysis_examples/refs/heads/main/tokenization.png\" width=1050 height=225 />\n",
        "\n",
        "Enough talk now. let's start coding.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c45cfb",
      "metadata": {},
      "source": [
        "# Writing an LLM\n",
        "### importing important functions and libraries\n",
        "I created a file containing all important functions that we need. All we have to do now is clone my repository by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "j7Wm1rtQqrtl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "j7Wm1rtQqrtl",
        "outputId": "890d0e60-4095-4683-f716-6cee3cf7996e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'analysis_examples'...\n",
            "Updating files:  40% (46/115)\n",
            "Updating files:  41% (48/115)\n",
            "Updating files:  42% (49/115)\n",
            "Updating files:  43% (50/115)\n",
            "Updating files:  44% (51/115)\n",
            "Updating files:  45% (52/115)\n",
            "Updating files:  46% (53/115)\n",
            "Updating files:  47% (55/115)\n",
            "Updating files:  48% (56/115)\n",
            "Updating files:  49% (57/115)\n",
            "Updating files:  50% (58/115)\n",
            "Updating files:  51% (59/115)\n",
            "Updating files:  52% (60/115)\n",
            "Updating files:  53% (61/115)\n",
            "Updating files:  54% (63/115)\n",
            "Updating files:  55% (64/115)\n",
            "Updating files:  56% (65/115)\n",
            "Updating files:  57% (66/115)\n",
            "Updating files:  58% (67/115)\n",
            "Updating files:  59% (68/115)\n",
            "Updating files:  60% (69/115)\n",
            "Updating files:  61% (71/115)\n",
            "Updating files:  62% (72/115)\n",
            "Updating files:  63% (73/115)\n",
            "Updating files:  64% (74/115)\n",
            "Updating files:  65% (75/115)\n",
            "Updating files:  66% (76/115)\n",
            "Updating files:  67% (78/115)\n",
            "Updating files:  68% (79/115)\n",
            "Updating files:  69% (80/115)\n",
            "Updating files:  70% (81/115)\n",
            "Updating files:  71% (82/115)\n",
            "Updating files:  72% (83/115)\n",
            "Updating files:  73% (84/115)\n",
            "Updating files:  74% (86/115)\n",
            "Updating files:  75% (87/115)\n",
            "Updating files:  76% (88/115)\n",
            "Updating files:  77% (89/115)\n",
            "Updating files:  78% (90/115)\n",
            "Updating files:  79% (91/115)\n",
            "Updating files:  80% (92/115)\n",
            "Updating files:  81% (94/115)\n",
            "Updating files:  82% (95/115)\n",
            "Updating files:  83% (96/115)\n",
            "Updating files:  84% (97/115)\n",
            "Updating files:  85% (98/115)\n",
            "Updating files:  86% (99/115)\n",
            "Updating files:  87% (101/115)\n",
            "Updating files:  88% (102/115)\n",
            "Updating files:  89% (103/115)\n",
            "Updating files:  90% (104/115)\n",
            "Updating files:  91% (105/115)\n",
            "Updating files:  92% (106/115)\n",
            "Updating files:  93% (107/115)\n",
            "Updating files:  94% (109/115)\n",
            "Updating files:  95% (110/115)\n",
            "Updating files:  96% (111/115)\n",
            "Updating files:  97% (112/115)\n",
            "Updating files:  98% (113/115)\n",
            "Updating files:  99% (114/115)\n",
            "Updating files: 100% (115/115)\n",
            "Updating files: 100% (115/115), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository and all its functions\n",
        "!git clone https://github.com/abdulrahman1123/analysis_examples.git\n",
        "\n",
        "# Add the cloned directory to Python path\n",
        "import sys\n",
        "sys.path.append('/content/analysis_examples')\n",
        "\n",
        "# Import important functions, including functions to build the model and train it\n",
        "from microGPT import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34da005f",
      "metadata": {},
      "source": [
        "## Shakespeare's Work\n",
        "Let's download theentirety of Shakespeare's work to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6c18a715",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of dataset in characters: 5376417\n",
            "THE SONNETS\n",
            "\n",
            "                    1\n",
            "\n",
            "From fairest creatures we desire increase,\n",
            "That thereby beauty’s rose might never die,\n",
            "But as the riper should by time decease,\n",
            "His tender heir might bear his memory:\n",
            "But thou contracted to thine own bright eyes,\n",
            "Feed’st thy light’s flame with self-substantial fuel,\n"
          ]
        }
      ],
      "source": [
        "url1 = \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n",
        "text = requests.get(url1).text.replace('\\r','')\n",
        "text = text[text.find('THE SONNETS\\n\\n')::] # remove text introduction\n",
        "print(f\"Length of dataset in characters: {len(text)}\")\n",
        "print(text[:302])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d473a959",
      "metadata": {},
      "source": [
        "### Hyperparameters\n",
        "Hyperparameters are parameters that specify how the model is built and trained. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hy6pLTNuq4EQ",
      "metadata": {
        "id": "Hy6pLTNuq4EQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_size = 8 # how many independent sequences will we process in parallel\n",
        "block_size = 16 # what is the maximum context length for predictions\n",
        "max_iters = 1000\n",
        "learning_rate = 2e-4\n",
        "device = torch.device(\"cpu\")\n",
        "eval_iters = 100\n",
        "eval_interval = max_iters//10\n",
        "n_embd = 64\n",
        "n_head = 2\n",
        "n_layer = 2\n",
        "n_embd = (n_embd//n_head)*n_head\n",
        "dropout = 0.1\n",
        "vocab_size = 10000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a69c484",
      "metadata": {},
      "source": [
        "### Create Tokenizer, Encoder and Decoder functions\n",
        "create Tokenizer, Encoder and Decoder functions. The encoder is used to feed encoded data to the model (numbers only), and the decoder is used to convert the model's output into characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "778a781a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 10000\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAABjCAYAAAC8P0kBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL59JREFUeJztnQV8FNcTx4fiDsU1hkRwggdL0AYLEFzTAMFpaYu0f1xK0RZ3d4K7BQm0uIfg7la8gVL+n99s9rhLcpHjZBPm+/ns5+52927fvjczb968eXuJPn78+JEEQRAEQRAEQYN8ZesCCIIgCIIgCIIxxFkVBEEQBEEQNIs4q4IgCIIgCIJmEWdVEARBEARB0CzirAqCIAiCIAiaRZxVQRAEQRAEQbOIsyoIgiAIgiBoFnFWBUEQBEEQBM0izqogCIIgCIKgWcRZFQRBEARBEDSLOKuCIAiCIAiCZhFnVRAEQRAEQdAs4qwKgiAIgiAImkWcVUEQBEEQBEGziLMqCIIgCIIgaBZxVgVBEARBEATNIs6qIAiCIAiCoFnEWRUEQRAEQRA0izirgiAIgiAIgmYRZ1UQBEEQBEHQLOKsCoIgCIIgCJpFnFVBEARBEARBs4izKgiCIAiCIGgWcVYFQRAEQRAEzSLOqiAIgiAIgqBZxFkVBEEQBEEQNIs4q4IgCIIgCIJmEWdVEARBEARB0CzirAqCIAiCIAiaRZxVQRAEQRAEQbOIsyoIgiAIgiBoFnFWBUEQBEEQBM0izqogCIIgCIKgWcRZFQRBEARBEDSLOKuCIAiCIAiCZhFnVRAEQRAEQdAsSWxdgITCx48fKSwsjBIayZMn51dr3pstrmkOkiVLRu/evbPY+Qm13r7keze3DCTkutRiXcXXurQG8fXe46Oc2arccb0mZCJRokQmXUucVTMBhfT19aWExsqVK/nVmvdmi2uag4ULF1Lr1q0tdn5Crbcv+d7NLQMJuS61WFfxtS6tQXy99/goZ7Yqd1yvCZlIkSKFSdcSZ9XMvP9ACYakiSPs+PDe8hdNnNTg43uywjXNQFJKGqdqMrjNj2a4x0RJE6wcalJOzYGeEGhFzvXlWEtVaXZ9sQaik9oTpHiok5bof2yikxH0Ia6Is2oBps1ZRMnCp0DiI+/CwijAr1WUxxbNmkbJkycz+zXDwt5RK/+AKI9NWzSNklngmubgXdg7CmgVudyzpi2i5Mkiy0DYuzDyD4hct4vmm1avXG9tAxKkHGpRTi0p67aUc2NyHJ0sWwNz64s1EJ0UndRq/2MLnYxOH+KCOKsWAMbI1FC31oEwWvveYCziW33CUMSlzJao14Qsh1qU04Qq53GVZWsQH9sXiE7Gr3vXqk5qUWct3b7yNABBEARBEARBs4izKgiCIAiCIGgWcVYFQRAEQRAEzSLOqiAIgiAIgqBZxFkVBEEQBEEQNIs4q4IgCIIgCIJmEWdVEARBEARB0Cw2dVabNGlCSZIkoTZt2tiyGMIXxO2bt+li6EV6+/atrYsiCEI84PnzFxQaepHu339ACY2LF0Lp0sULFN+4ees2hV6If3Zc+h8rOKsVKlSgRIkSRbsNHz48Thd/+PAhffjwgV8FwRp0adOFyrmUo1PHTtm6KJojeN8eypQqEfl4V6Mvnes3blKiNJkoXxF3Wxcl3rEveA+lyZSI6vhoV46uX79JiZJmonzOMbfvmrUbyaVwOfplwAhKaJQr7kIVSrpRfKNNhy7kUrIcHTvxyY7v2RfMOqtu1er4RPqevWsxg3Nu37lj1XJL/2MFZzVfvnzk5ubGW65cuXT7CxYsqNufPXv2zyjKl8e9u3epS4e2VNAuK+XOlIo8y5ekDWtXW70cY34dxk7KqGGDrHI9/6492VDMW7TELL9XzL4YZUqUie7cVgzPqeOnKFfKXOSQwYEuXbhECYFBQ0Zx5xpxGzZiLH0J3Ll9m2W0mLO9WX83SfqsLIuWBA4vrgEHWLAuSVJkZT350vjrYDDrS72aVehLIWuWzNS0kQ9VreRh9Jy6tWvyOalSpbJq2b4kqnjVs4jOxfrvVufPn697P2/ePGrfvj2/37NnjzipJvDixQvyruZBN65fo2zZc5BHpap0ITSENq5fTXUbNLR18eItT588pbYN29K7d+9oXuA8yl8wv8Hx9XvWU3ykkJsLNW3iQyEhF+jM2RByc3Pmfa6uBenU6XO2Lp4gJFjatW3BW0LkyZuPFB/ZszWyHXd1caZl82dxhDVoX3CU35s4dpQuwnrj5huyNvG1/0mwOatwFEaOHEmFCxemlClTUurUqalUqVI0a9asaL8XFhZGnp6enMeKV5XXr19Tnz59yNHRkZIlS0ZZs2alVq1a0c2bnyIVq1evpqRJk5Kvry9t2bKFypYty/9TmydPHpo6darBdU6ePEl169bl30H53N3dafv27brjgwYN4v0dO3YkSzF35lR2VAu6uNJfJ0Np2ZpNdDzkKgV07RXltOyQAf0oX+5MHIGdMOZXPv7vv//S0AH9yc0pF+XIkJwquBeidatX6r7/8uVL6hHwLRUtaMfHnXJ9Te1aNKYH9+/z8SUL5/HvjxzyP/7824jB/DnX1ynp7ZuoFfnVq9cU0KM3ZbErQCky5aQyVarT7j37dMdHjfudnAqX5GM5nFzJp1lrdszBoOGjOMI0e/4i/tw+oLtuOsYc/PfhP/Jv5k+3btyi/sP6U/VvquuO+dby5eiruv0V/JfBd+tVqcf7x48cTyWdSpLT1040eshog3PGDBtDjhkdyS2XG03/fTqfX6ZgGbIGjRvVo2WLZ1ET3/rK54bK54YN6pj8m//88w919m9DeTKnpnIlXOncmchTU5aWwa4d25FHqcLUtME3PMMwffLv5GyfjcoWd6FbN2/wObh+kQJ5+D324TO2sb8OM/ne1elApCEBVQ7bdeoa6dwBQ0dSuhx25Fy8DB05dly3f1/wQfLybsC6kCxjdnJwK87yr1KlVj3+zStXr/FnHMfnGvUa0+eweO5iKl2gNGVPlp1fl85fqjt28/pNlkv3fO40tP9Qyps2L5VxLkPHj3wqN7dZ/6EsxzmS56AKhSrQhsANnyVHHTq3oax5UlPJcq505lxkOfpt7HByL+/G52Cr/o0HHT6i6ODuoB2cNlC5Wmnd+ZevXOJ9LkXt6L///otzmezzFePojq59w2ci2vlF0b6DRlK6r+3IuVAZOqJXT8uWrzaYxfDv2DPSd+fOW0xuRctTyrS5KEuOAlTzm8Z048YtMhXMbkG2f/quG9X2rEB5s6RhfUEdq4wdNZzKl3RjvcX2jZcHHTms1OXNG9f5+97VKvLnA/v36vQF9l4lZ8YUuv1Z0yaJctavfUtfssuWjje8V3VW1Vt8d/igX1h/cU7v7gEm3/dPvwxi3bh7757BfsgqdKtFe6UvrtXA12AaP/igoR23FV3bdWW9GzdiHDXwakA5U+Qk52zOdPni5Vj1P7CTPf17kmsOV/5uCccSNOCHAQbn7Nq6izxLeup+u0/3Pibnvg4fNYj1a9QYxYYuWjKPP3ft6R8plef7n7qxzhYu6URBe3dRgnFWYRy8vb2pf//+dPbsWcqYMSPvP3r0KHXo0IH+9z/FMYqKnj17UlBQEDuZv/6qdIbv37+nGjVq0G+//UZ3796lvHnzcsMuXryYPDw86O+//+bz4BBBsLdt28bXv3LlCju9t2/fpi5durADC54+fUpeXl60ceNGdqpz5MhBJ06coAULFujKceDAATYOe/fuJUuxZ/cOfm3r15HSpUvH75H3W7xk5ByqQweDaeaUP6hw0eJUqEgxevRQSfQfPvgXmjBmJNeXZ/VadP/eXfq2dVM6cuhPPv7s6RNavGAOpUufno9nypyFNqwNpH4/9ODjdvYO5NO4KbkWKsyfnV3d+HM9n8aUOHHiKMvdudcPNH3OPMqWNQtV96xCZ86dJ+/GzXmKc+2GTdR3wBB6+uwZ1aruSU6O9rR5+0568fIlf7eQqwtPwTg6KFO5pd1L8Gds5mDYz8No7869VN+3Pn3X7zuDYxWqVCCfpj6UOUvmaH9j8pjJ5JDPgZ7//ZxGDRpF165c0xmKkf8bSf+8/Yec3ZxpWH/THSWtMHXieFqxZCElTZaMcuTMRUP+19fouZaSQXD+3Fl69eolPXv6lPr/2Ivs7B3p0oVQWrVcSROBTNbyrsfvMX2Hz9gw0DMVdToQOgdUOSzjXtLgvNt37tKK1Wspb+7cdOHSZerd71MHsnvvfjp87Dg5F8hPtWt40aPHT1j+N29TdNuzckX+zTRpUvPnOuHXrFKxgsnl3r5pO/Xw60H3796nip4V+bVbu24sn/rcuXWHNq7eSHns8tDlC5dpQO9P5R7+y3CaMHKC0ma1PPk3OrfuTH8/U2xpXJk0dTwtXbGQkiVNRjlz5KKBQyLL0byFM+n161fkUb4yFSlUjP48dIBatmvENrtKZS/+3rETR+jGzet8/oZNa/i1Qb1G9NVXce+m6nrX5JkIXfs28eGtTOkI7Xv7Lq1YtZby5s1NFy5cpt4/faonu7x5+DulS5WI8honTpwmvw496Nq1m1TNqzK5uTrTgYOH6fYdQ4fLFBbOnUkpU6WirxInZn0JDNcF9djrV6+ovEdl1sVDfx6gds2VukyVKjXrRqWqXnxu5ixZdPoCe69Sv1ET3hcVHz9+pNZNG9D6NavI3t6RN7xv2zzyjN/0yRMoZ87c9C4sjObNns6DW1Mo5OrMrxcvXTHYf/XadfYB1OPQHehQlszR23FbMWbIGLp66SpVrlaZUqRMQW/fvI1V/4O+ZdHsRZQyVUryqu1FadOlpS3rFJ8FnD97nprXaU4Xz1+kKtWrUOasmWnWpFk06CfLpu79eSiYtu3YRC4F3eja9avUrkMzg4GTNYl1GkBsWbZsGe3cuZPfL1myhJo3b85OoY+PD23evJlGjx5NvXv3pgwZMhh8b9GiRTR9+nSOjiJKWrp0ad3vHTx4kPNk4fAi5eDBgwcctb116xatWLHCIAIKR7Zly5Y0Z84cevbsGeXPn5/3rVy5kmrXrs1RVTisMIDXr1/ncmCB1x29RGs8pQD78Gop7txWRt/2Dk7cSf/Yq4vu2KwFywzORWRh256/qHDRYvz5+d9/84hq+qQJnEKw/8gZ7sT/PLCf6lSvRFP+GEdzF6+krzNlpgPHzpFzeKeOenDInp6C9wXx5woVK/OGnNWQs2eoXoPG1OeXQSyMfi19I5X59Zs3tHHLNipRrCgd2beT63Dh0uWc7D55xmzKkT0bn9fF349H3ODhw0eULl1aft/Ypx5vyFmFEers357atVKm18yhAKsWr+LX1OHOgT69+vbSRVAf731s9Df6DulL/l39qXHNxhS0PYiNhIOTAxsSMPC3gdSpRyeaOn4q/fK9co/xlcAVSgc4Y+4SqlazNjuKiGxGhaVkUGXVhu38vTu3b9LaLbs5eqvqCPQBOatbN61nZ1fVD8jM6hWfoopxQZ0OXLV2PQ+wMX1orOP+c/c2CnsXxjMFZ0JCdMeaNfah77t31g02J0+fRd169+EpyG9qVqcB/X7U5ay+enWNJo75lezt8nK5fVv7mVTu339V2mfygslUt2FdWh+4nto3bs/Op1ctxUFR2fbnNr6WW043CjmjlJvbbMJ0ypYjG+0/s19ps/1/Up1Kdej61euUpWSWOJdpRaAiR3NmLKEa1WrTT/170ZTphnK0cM5KKlHcXec8VvIqRcdPHqWLly+Qq7MbNfNtReP+GEVr1q2kXt1/pPUbldz9xj7NaMIkwxmO2DDx9/D2DQxv38XRtO/+bTyrlyOPK6fYqJQrV4q3efOX0GG9iKvKtetK5L9hA29atGC6Lmjy9u3n2zIMzqA/40ePpGED+1PIuTO6Y3MWreSghlqXXh6l6OTxo3T54gUOOEA/kLO6L2gXFXR2jdSfgKmzlODMmlXLIx3bt2c3nTh2hAoXKUa7DhzlOqrmUYoHoPv3BlHFylV157bv0JkGjxhN33frRPPnzKDQkLMm3S8CGeDi5Sv0/MUL6tSjNw3+uQ/lzJHd4Hjf3r10sxZ7g43bcVtRonQJCtwRSMmTJ2cnG1ts+p8bVxVZGjNtDFWtXlX35ACViaMnshxPXzKdvBt4sz0u61yWlsxZwufDb7IE6OP37DhMmb7ORBW93OnU6RMUtE/x74yROPFXJg0wYyyLuX9QjWDCSYSjCjB1DwcVwCjA6dTn6tWrFBCgTCFMmzaNI6kqiJSqRqBatWpUqFAhjowiNQCcOxc5Xw8OMa6ZLVs2nuIHiLACFxcXnuJHY/v7+1NwcDBlyZKFihcvrvs+IsCnTp2in3/+mSyFamjw+ubNGzYa6haRYiXcdU4CSJ8hA127cpnr8sH9ezwVhCkZdPbg0sVQfv3w778cDStSIC9lT5+M7LOlY8MD59gUXr18xa/HT56ixOmy8DQMHFUQevESNaxXh0e8I8aMJzf38tS9dx+6decOR3CsATrg9BnS07L5y9jJNAWXQi6639K/52uXlQhr1RqKIUFEKr6jTrN7hHc+lasaX71taRlU04VSpEjJ70GYjUbw+qCzzJgxA2XPpsjDy3B5AI+fPCWf5m0oc978rAtwVAFmFixF6DmlXqvVVtpKTXWJKO/Zc2anDCh3eGevL8fcZvceUJ7UeXhKEo4qeP1Ksalx5dYtRY4qeShyVLVyZDnau383pwhgOhHTi3BUwbNnihw0b6o8vhDO6r17d+no8cPk5JiPSpb4lBpgCXLmDG/f7JHbNya8PCtTvnyOtHjpKnIsUILTBI4dP0Xp0yuDl8/BxbUQv2IgCF6Fz06B/Xt3c9qOqnNwVPXr8nMJPa/0qVWq1eAZNsxQ4j04H8EZdY5Yzlexrz99XJ0LsoMDZ/XgocP08NEjOvDXIf6s76xqHd9WvuyoAjiQsV3I1cKvBZ/ftHZT8q7ozbN6XyX+5J6FnlX0vo1PG9bZLImz0JVLV9iPUX0hS1DItQhlyZyF26ZyRU8DfTdG5syZeNN8ZBVRT5A7d26D/fpPEFBzGPXBFAZAFNXPzy/S7yEiE5VjCofUmCMI4LQCRHcBpv03bNhA3bt3p8DAQN7gwGLRmBrNtQa5cufhkfC1a1eoRm1vTnTHyk3kGEUE00ERQYcPMmXOTJWqGEZUEH0C/X7sScsXL+DOHw5JhgwZ2Rk2JQeMr6k3PVa2lHskY4OoUejxvyhw3QbaGbSX5i1eSlNnzaWta1dQtaqWX5U6bdE0On74OA3tN5SnR5Zvjuz4x4Sx9AdVPr9UbCGD/300TU7NiTF5gA37plFTdm4g9xXLl6V7Dx7QoSPHdHmSWiz3pzbLRJW8lIEFQJlPHj1pkbIsXDyXBgzpy3a5TKlylCNHLgo+uJcePVIeXQhcnF2peNGSnAowadp4LmeTxi3JVvUUG+CUnjy6h9au20w7du6htes30+y5i2j6lHGfXS5M/0fF4gVzOV0HdVmqTDlO3zkYvJcehT8G0tp8Tv3pg4CGk6MDO6cI3tSq7sWPpUqRPAUPYh3s7WL9W2r/r8p69OeQWcE0vikgWnow5CDnju/btY/GDB1DsyfP5n1IHfgYXtAa3jUMZg7R5k8ePfnsckdXV3EFM6x4MoPmI6vp06fn1/t6ydhAf5o94tMDsHBqwAAlV2j27Nm0detW3bG0aZUp5KpVq3KFRtyQGxtXEJkNCQnhqGrlypXp/Pnz1KBBA7M2WExU8VQiIovnzzZpZOTglE8X+h/z+1Se6sH2+9TZnAcLTp04xq/jJs2gVeu30a9jJ0b5W+pIUHXojZE2XElSp0pFC2ZO4alTbFPGj+Yp0Tt371KSJImpQ/s2tHzBbJozRZm6WLdxi+H1dAMIZYrEXDgVcKJOPTtxVHTnlp20P2i/2X7bzlExlsiJBbu37o71d12L2XM0CUnrWiJPXuWegvcqU/J7g6Kf3rGkDMZEbGXUWr+LThWOatq0aSjk6EFas2whNapfN+prRBgwfw7IlwaQb7Bj8w6DGYGYQD62rs2mjqFZy2bxNnbaWMqd1zDAEFvy5FHkaF+wIkdBew3l6MQpRQbatPSjnVsO0MI5KyjT15E7sxbN2upyYEFTMzirlpIb8OTJU3r9+g21bOFL8+ZMpi0blMHxuvWbyVKo+tSyjR9t2X2A5ixawak2EUmWzPT7dnZRnru6Z+d2tt/Y8F4/4msJCrk408VLl+nYyVP0XbcAzhE/cfo0uToXMAhAxcTX4etkboY/yjDac259mmq3JYiS5rXPSz379KTA7YHULqAdPXn8hA7uO8jHC7gW4FefZj46ncXm382f0qRNE+frpUmtfOfFy+f8ev2mMnMYkbMhp+nR40ccXMDsiL6+G2PCuBF05mTUT2PQlLNavnx5foUDuGbNGl2elLpgCivw1al5fX766ScqVqyYbhr++XOlEsuVK8ev+/fvp127Pi0iQC4IHpsV11zHS5cucWoBKh9/dNCtWzfef+/ePXr06JHOYUZaAJ5oYCna+QdQXjt7OnfmNJUv4UotG9ej40cPx/r7mF4I6NaLnjx+TKWLFuDv16/tSYXz56ZF82fzOa5uysKpG9eucmR69MghUf6Wo5PyeKeF82bSj7260oB+P0Rp5DDCbVi/DoWEXuA8vAbNWlGlGnUoj3MRXki1Y/ceypHPjfc1bN6GevzYj78XcVScP58Tv44cO4F6/NCXev0U9wGHMRDB+3GAkis48MeBPAAJDQnlpwRguxCi/FsLplnwec7UObH63ebtlJSWgT8M5HxWay+wQu5ds5b+tGLlOuXzauXz6rUbTf7NRk2UfOGO7VtQwzrVacGcGXH6vjllMCYQvUXqAVIO/Fo14fzaoPAO9HPI7+TIr/WatGQ5XLJCyXuOCScHB75/DLhu3LzFOdgz5y2M+hr5lGu0C+jG18Bsg6n07KusSO/apis1qd2EurVV7Fevfp+eIhJjm/UK4I4QTxJoWa8l1fesz08PuG1ix92kkSJHfh1bUN2G1WnuAkM5cnNVZODuvTssAysCl1LohU+5oSq+jZqzIw3nyL1EacoXbpc+B7Xu6/m0pF7f96clS2PXvqB7zz6sY1OnK+0VtDeYP2MDyG/NbV+YynnUpEZN2lLT8P129nnJUqj6dO+uUpeBK5bShfOR6xKLqRD1RJ+ClfvQl2NHlP4Fi6X82zTjDXBKXPhnzOxVquJJxUuWojOnT/Kzv7HhvXvpsgb5quYGU/1wUDGL5Vm5Es/gHT1+UpcCEHI+lJq19ecNfRAYNGIUf54685Mdz+fkwKkdl69cpfJetfj4giWGebulSihpf03a+FGT1n4U0FNJU7QEsel/xg0fR4VyFaJGNRpRi7otaOlcJRcfDizo8VMPbs+ubbtS/ar1+ZxS+UtRq/qtTCpTIbci/Lp42XwaOKQfzZg1KcrzoItVa5ShqjXKcr5qpkyZqWql6P/sY8iw0Tod0bSz+u2335KDg7LqsGHDhpwOgJzQHTt28Oho/Pjxuql5fZAXg0VR6gr+Xr0U44u8Ujs7OxZg5Kzi95ycnDjiimjr5cvKoyFiy6FDh6hWrVr8lALk1TZr1kznFMORVhd1YSEWUgMsBRZlbNyxnxo3bcGrZPfvCyIXt8I0Y17sH5T/86Dh9GO/AZQ6dRrauX0LhZw9zUnx1WrU5uNDRo6lmrXr0KTfx1CZIsrILKrE51redcm3eSsWTDxSa/b0yZxrGBXTJoyl7gEd+NxNW3ewccEKzQplS1OxIoXJq0olunz1Km3atoO++ioRde34LXXrZCi437ZpSd61atCTp09p4rSZ9PsUZXGCuWjt35oc8znyv4QELg2kxw8f05rla3h7/EhJbsdUCz4fO6REKmKijk8d+v7n7yl5iuR0+vhp+q6/8rQByGt0QG6fPH3M01zOBU1fvX723HlavmKNbgHIuXOh/BnPXTWVzt2/o0ZNmnNuKDq/XwbH/R96zCWDMQHb8dv4yWTv4Egb163mhWBxGdwZY+yIIZzCgpX9kMPtuwwXfhkDneGyeTPJ0d6OSnh4srNboqjSAURk8M99qWTxonT85Gm+xpr1m0wuL6YB/5j9B88eQIaRmzpx7sRIi6ui4+fhP/OADtOJiNCGnA4h1yKubKdNoVvn79jR/CfsH3ZIB/1iKEftWvtTQIfuHGF1LpKHVq1eSi7Okf81KXOmzORVVcmNNFcKwNjRQ/hZxLuD9tPvE6fT9h2xa1+wYdM21jF1cdXVq9f5MzZ1EO7TwJvu3L1HGzdt58f6tWzemAb8/ANZitbt/alD5+506uQxfpwbFhhiUVVUg7tBw3+jrNmy8xM/oC94jrf69A399REY0Kuf8ThF6NrC5WupboNGnKaGDe/nL7XsH9aoTql78eLsmJUr7W6w/+Gjx7Q8cA1vjx4rdnzXnn38+dDRYwYBizlT/uCgyOGjx/k4dE8fBGRqVvOk5y9e0so162jtBstFw2PT/yD3HDOD6LP27NhDOfPkpN8m/0bFSioBPLcibrRs0zJyL+vO3wkOCqYkSZNQm46m/VW9Z5Xq1K5NB/rn7Vtav2kNNfWN2uktV8aDatesSyGhZ8nRwYnmzVga4xoU6JqqI+Yk0UcT5r7XrVvHK+UhFNeuXdM9nkoFKQB4RBWm8/E+TZo0nA+K6Cmm4FXgzK5du5YdRjw5AAwePJiGDRvGworHTyHXFVHPgQMHckQUj6/C6BsOMZzOESNG8FQPorgoEyoSz19Vy9SiRQt2PjHNj6cMYJU/HpGFKC0ee4WUBDzqaujQoZQ5/HEYSEkYNWoUtW7dOsZnw6rwCl9fX3r/gWjO4pVWW1RkCdSnASRNTPwUBYB7ow/vaeXCORa5N90K6cRJDa75nt7TnJWWuWZcgNOJGQI1LQWPCkJkC8YD+X9JKSktXLiQZebDe2X1M8p8/MRRqlStFBuGSeNn8H229vPFberOp4/vaeUy0+6R662ZHx4kaVhvCUAOtSin5pZ1VQZsLedcl75+LMf6dakvy5YGEb5SFQrRlauX6MKZ25Qtazaz64s1EJ0UnbSF3i6Mov8xFaSsfVO/KlWp5EUb1xim9cRVJyPqg6nlMmmBVf369XlFqTHgAM6cOTPG34HzGBE4pdj0waKoGTOin6LEo7HUx0ToAydYdYQBoqdLl0b/uJshQ4bwJggqeO5qcYfiVLp8aUqXPh0/1grUqluLjvx5xOj3/jx8gCMVPbpYbppJEOI7/Qf8QCHnz9KFi+epccNm7KgKgiBY7GkAgpAQwfR/keJF6MSRE/wYoKzZs1L7zu2pQ48O0TqrXTv15E0QBOP8MXksp4eUK+tBo4ZPsHVxBEHQGOKsCkIsQCrLxn2RFzPZ6t88BCEh8epJ/PyPekFIiFTyqKI5nTT/3wwIgiAIgiAIgpkQZ1UQBEEQBEHQLOKsCoIgCIIgCJpFnFVBEARBEARBs4izKgiCIAiCIGgWcVYFQRAEQRAEzSKPrrIA76L5w4T4Xv6wsHcWuWZ0v/vOQtc0B8bKFvYuLG77TbzH6OstfsuhFuXUHBgrmy3lPLprG5NZa2BufbEGopOUYNpMy32PKf2PLXTSXO0uzqoFCPCL+n92EwKt/AOsfs2AVta/5ufiHxA3GWjV1vz3mJDlUItymlDlPK6ybA0soS/WQHQyfqFVndSizlpaJ8VZNTP4T+QEC/4M2MrgP48TfDUlMv89Jmg51KCcJlQ512RVWkBfrIHoZPxCqzqpyaq2gk4m+vjxo7b+piCegmoMS4BTPMmTJ+dXa96bLa5pDpIlS0bv3r2z2PkJtd6+5Hs3twwk5LrUYl3F17q0BvH13uOjnNmq3HG9JmQiUaJECd9Z3bZtGx06dIjy5MlD7du3530nT56k9evXs7MIUBEpUqSgzJkzU/78+cnd3Z1Spkxp45ILgiAIgiAICT4N4O3bt+yUvn79Wrfv77//1jmqWbJkof/++49evHhBt27d4u3IkSPUsmVLypYtmw1LLgiCIAiCICR4ZzU6EidOTF26dOH3Hz58oNOnT9PmzZvp5cuXtHTpUurWrRslSaLd20U5N27cSA8fPuRyVq1alXLmzEl//PEHZc2aVXdeQMCnJObt27dTaGgoR5NxfqFChXj/P//8Q6tXr6bHjx9z2L1BgwZmd9b//fdfWrFiBT158oTLmz17dqpTpw4lTarkrmAAsWDBAh5g6JcZYLAxZcoUKly4MNWqVcus5ZowYQKXR23revXqcT2eOXOG9uzZw+VycXGh6tWr8/E3b97QunXr6Pnz51yPHh4e5ObmZvL19+3bx9H+Z8+eUadOnbheHjx4wG2Ldvnqq6/4vnGd6L6jElU94tytW7dShgwZ+DPuD/dpCaBHBw4c4Lr5+uuv+TqYuTClPnfu3Ennz59nGUmVKhV5e3tTpkyZyNYYq/+9e/fSuXPn+D4yZszIeoR7P3v2LAUHB+ums8qXL89tai1Q7yhbnz59uJ6NyRb23759W/e9R48eUZMmTahgwYIW1bf79+/T4cOHdeegjMWKFaOaNWtaxQbExVZh/40bN7jP6Nu3r0EQZM2aNXTv3j1ydHSkZs2akZb7CldXVw7ObNmyhadlIQstWrTQ2Qhb9hXmbDPIEsqLoBRsD2ZPvby8+L5spZfz5s3jegSwE9ABdTbXWD9orD0uXrxIu3fv5ratUaMGlS1b1qJlXGFE/mHf9+/fz+WDb4Uyoq5NtVOwm5+Ldr23zwCVW7x4cVZadOoQcAgyDCY4evQob0+fPmVFsLe3p7p163LjodGmT5/O32natCkbKmuwadMm7ribN2/OAo5O//3795wTEtHZA5cuXWIh69q1KxuvmTNnUr58+VgoIGQQSBirkJAQ/m0/Pz+zl7lMmTLk5OTE79euXcuGAkINUL+pU6dmJY0qncPOzo4sRePGjQ0cPpQBctCxY0dKkyYNzZo1i65cucJlh6MCg456Rz1OnTqVcufOTenTpzfp2pCXIkWKsHFQQacI44DIP9p0xowZlCtXLnJwcDD6HRVj9QiZtXQHCocCnV/nzp0pXbp0bGDhcKJzMKU+UeYqVaqwzp04cYLTd9R0HlsSVf3fvXuXHVjoF8obGBjIDlilSpVYz+CAw5CjjiZOnMj7rJFuBEcQTnVsZAudu77zBRuh6qsl9Q2DpxIlSvB72DLUT0SnwdI2ILa2qmTJklSxYkWaP3++wfmwu5BzOA2XL18mLRFVX6E6d+jHChQoYJBHqIW+wlxthoEYbAbkHg7r3Llz2cHDAMxWeokBIAbfYMeOHWwD1YFZVPY7uvZAQMDHx4cOHjxolTKWNCL/sOHt2rXj72DAgDJ+//33rBem2ClzkKD/FKBo0aK699evX+dXdEBQSES70BAQbER7MIIGEHJEIKDsd+7csUo5IcgwiOgIAcoEAY8OjMqgmHDMIVjooFSjeuHCBd29Ozs7s8F99eqVWcuMDly/48NoHB0iwCvKB0WICAxi2rRpDaLFlgb1ojpMqC+MYtHmAIqIHGiAcsFYXLt2zeRr4TpqNEMFvwlnAsDIoqPRV+SovhNTPVoDXB/OKBxVAAcITqmp9QmDrEbg4Nyo8mJrjNU/OkM4AXiFI6jWAzoVNXoD3VXPszS4Dpy8atWqxVq2VDA4QDtZe3YJdhcdHBxYW9mA6GwV9kflzKBvyJs3r+Zm44z1FdgHfYSjClDnqmNh677CnG0GGVdn76CT2FTds5Veqk4grofrqtc0Zr+jaw+stcG9mroIKa5lNCb/sOHqd2BjQGzlIio7ZQ60pYlmBsKLhkDjqBWtdpxQTERO1SgKRpcAnTOOIbJqiShEdE5BUFAQG3cYckyNQWHVaAlG0IhWlCpVir+DERmcB4ySEKHAd5CrC/AKA7Z8+XIePeG3sQ+vlgDRaEwbqFFVDAYwhRExGogIAEaMbdu25allSwAlx/Qd6gsRM0RHUFeoH0TX4UxB+W7evMnnwzDAAYPxwDEMVHC+JdsagyD9qJcxjNUjQPkRtYR8I1qJqKW5QT1BbzBFCCcIRhZyZI76VJ0nrQLnqnTp0jR+/Hjd7Is6M6PaEaQZoT2RzoD6sDSIgmG619i1jMkWOg/UN6Jn1tA31ZkAx48fN6g3a9iAuNiq+IaxvgIDFNj8JUuWsI7myJGD92NqX0t9hTnaDE8XQEQV9gWyhTQkW+olWLVqFV29epWdTXXGy5j9jq49rF3G2IBABOy/6rR+rp0ylQTtrALk7gCMYgCUGHl4aDRUKqb/9Ef9OF91Yq0FRjlwjjHCql27Nh07dozz/mDQe/fuzSMcHEfui/7oGai5ghgh64P7tdZ9wDggCoGcFpQdkR44LWo0WwVTx4gI6Hdm5gZTRIiAITKOqSMYddXwqs4RDJ8KpkBQLqR+oG4xQLFUNAVlWrlyJbdxTJ1BdPWI9lejZDiG6T/ka5u7g4EjjBw21CM6DDig+m1nan1C/zCTAfnWKujsML3Ys2dP7vCRBgAnC3lwAJ0NpvEw3QVdxQDXHHlZxkDECzYLU3NxlS1EbeCQ6E/VW1Lf0EGrjinqEGWypg2Ira2KjxjrK2ATYAuQmgOnAm2B/k0/uqWFvsIcbQZ9RGocZkFh+xBswuyILfRSPxUGNhK5xLCHsHnG7HdM7WGtMpYpUybG7yDYsGvXLl6kbg479TkkaGcVIxr1yQHqFB6iJTCieAQWEplhXNHpIhoR23wMc6N2LuoIEfk3CKPrL1xAx4/9WDABw4T70R+NqaM1oB7D7yKqguiYev/mBoKMjkqN5iDChkR/dFKICqP+kQsI4UXZYViQ+4g2QDQGhlJVWnOg3ifaEqNuRG8QjUaOkIoaGVQNX/369XXHkH+pRtnN3cksW7aMy4RRZ0xEV4/q9AxAxA9TSTASloiGQObUBTnItULdoI5NrU/cD5y+Nm3aaG6KVR9MVSMCodY1dBMGXnVWVeAA4hwY6Ni0q6lAHuCkTJ48WbcPeWSoRzii0ckWopvI4bcEUemb/qAEgxV9ebWGDYitrYqPGOsrMOsG50hdsAjHDvUPtNJXmLvNIPeQL9yn6qxaWy+jWiuDiCqub8x+R9ce1ixjmRicVQzYMRho2LBhrKOq0dkpU9eBqGi3tzAD+itS1YVSiJx6enpyojZW+iIUj04IAmTuHIvYgs4cwoARGIwMGhwdJYQYCgcBw9QHpjgQuQIYMcLRhsDBwGD6D0KlHoMCI2KMURtywyzhyCDhHbm/GJWrOTZIDlfB/SCSoo6yevToYbBSEKsTzdlJqasdMZJGJ4h7x8gWBg0LhdQpL0xfY7oSwBCi7Ij0wLBA0ZBbaU4wmkXUCwZJTeOIiejqEUZEzbHEFD0+q3mL5gZGFnUGg4v2hkNian1CfrFAq1WrVgYOjBaBPYAO4b5xL2gD1RFA1AY6BVuCOsDn2BpzU8HzorGpDB48mDp06KBb0W5MtmBD0GHrDyAsrW/6TnJE/ba0DYiLrYqPGOsr0L+hL0NfAFuP/aq8aqGvMFebYeofNgcyhwAAZBv3YCu9xIALNk+1x7B56iIpY/Y7uvawZhmjA3YDKSXffPMNR/E/107J0wCMgBEiHFAIO4Ayq9EhVSGh9BhhIA8PjQelUL+L3A50shjNIW3AGmC1HsLzGEki4oRVncj9w1QOPqMzwIpadZQIhwHHJ02axIqMKSFVIOCIY9oSqyER8cBUrrmBMUBZUbcYOQGMbm0ZtUCboe1grFBfMMCYkkS0D/lYGNmqj1pS85GhyHi0GRxKdPxoh8+J+CFaj0V8MEKLFi1iOYMTgagkyocBkhrhV1dMR/Wdb7/91ug1EL2CkUZ5ca9wRCyVm4UoKKaRMViCDuFecE1T6hPyjQ4GRhDgdzBtaWuiqn+siEZkBOkMKCfkXB3Mog0hZxhE4v6RS2eJKfbYgLJEJ1u4L8zEWGJFtDF9A6g7OKLWyvs31VYhtQpTnZDvcePGcaoLZBuzcsgJVxfw4Bj2f85j7SzZVyBqBccC8ou2gAyrAxRb9xXmbDM45Rjk4D5gY/BZHaTZQi8hJ6g/yAiuCScQubLREV17QJc3bNjAugPfBPbX39//s6Ld0ZXRmPzDmYbDiqi9CmTDVnYu3v2DFfJwTp06xSNGPDdV/1leEf8UAEYGQIlbt26tG2WicRDhQeOr0x4AjYcRAb6LRRUAEVg1kikIgiAIgiBYn3gVWVUfNaX/WCeMErAPPjdGCBjlY5SCiCgiQXhshPofxaBcuXIcEkeOH8C0FUZm6uMlcA2M5hA10F94JQiCIAiCIFifeBVZFQRBEARBEL4sEvSfAgiCIAiCIAjxG3FWBUEQBEEQBM0izqogCIIgCIKgWcRZFQRBEARBEDSLOKuCIAiCIAiCZhFnVRAEQRAEQdAs4qwKgiAIgiAImkWcVUEQBEEQBEGziLMqCIIgCIIgaBZxVgVBEARBEATNIs6qIAiCIAiCQFrl/yaZO7xzjSngAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 700x120 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "encode,decode, tokenizer, vocab_size = tokenize(text, vocab_size)\n",
        "\n",
        "# check what it does\n",
        "check_sentence = 'Greatest King, I dreamt that one day this nation will rise up!'\n",
        "plot_sentence_tokens(check_sentence,tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a07c66b",
      "metadata": {},
      "source": [
        "### Encode all text\n",
        "Now encode the entire Shakespeare's text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6660e4e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89506964",
      "metadata": {},
      "source": [
        "### Training and Testing\n",
        "I guess you are now familiar with the concept of training and testing. I wrote a simple function that splits the data into 90% training and 10% testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8eccc907",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size = 1410580 tokens ... Validation size = 156740 tokens\n"
          ]
        }
      ],
      "source": [
        "# split into training and testing\n",
        "train_data, val_data = train_test_split(data, 0.9)\n",
        "train_data, val_data = train_data.to(device), val_data.to(device)\n",
        "print(f'Train size = {train_data.shape[0]} tokens ... Validation size = {val_data.shape[0]} tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "317d5faf",
      "metadata": {},
      "source": [
        "### Creating the Model\n",
        "Now we want to build the model and some optimizing functions, and then train the model. The model is a deep learning model that learns two major things:\n",
        "\n",
        "- Different embeddings: You can look at the embeddings as a vector of numbers that represent a character. The model learns the embeddings of each character.\n",
        "- Word affinity: the model learns the relationship between the word and previous words to understand the context better\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/abdulrahman1123/analysis_examples/refs/heads/main/story.png\" width=800 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cc300ef2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BigramLanguageModel(vocab_size, n_embd, block_size, n_head, dropout, n_layer, device).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(max_iters=max_iters, warmup_steps=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb4f759",
      "metadata": {},
      "source": [
        "### Train the model\n",
        "Train the model for 1000 iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "cb6b1973",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0: train loss 10.0525, val loss 10.0516\n",
            "step 1000: train loss 5.6007, val loss 5.7831\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43meval_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m\\\\klinik.uni-wuerzburg.de\\homedir\\userdata11\\Sawalma_A\\data\\documents\\GitHub\\analysis_examples\\microGPT.py:273\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, max_iters, eval_iters, train_data, val_data, batch_size, eval_interval, block_size, device, optimizer, scheduler)\u001b[39m\n\u001b[32m    271\u001b[39m logits, loss = model(xb, yb)\n\u001b[32m    272\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m0.1\u001b[39m)\n\u001b[32m    275\u001b[39m optimizer.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sawalma_A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sawalma_A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sawalma_A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "train_model(model, max_iters, eval_iters, train_data, val_data, batch_size,eval_interval, block_size,device,optimizer,scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed27671",
      "metadata": {},
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f2f56aaf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " To be, or not to be  weary\n",
            "Which II given such man Warwick voices; and for a term up of to ext, if speak,\n",
            "Look shame so sonreak did partneroral see to know than his OF in the KingExeuntland sha\n",
            "Hold shall say fly.\n",
            "CHARMIAN,\n",
            "EVANS profession b.\n",
            "in dire; and Moor\n",
            "illo son utmost my aid,\n",
            "f ease worship paper understandound.\n",
            " [_ sight.\n",
            "By hand.\n",
            "Why. scars\n",
            "He’ Po, Gower. tax force wereigous great same happy. When ste,bsILIUSé be ra hither to themselves\n",
            " wideFor? But, I sad aSO theorns.\n",
            "\n",
            "T plants strew promisethen it, I fast’ouch?w the that his you,\n"
          ]
        }
      ],
      "source": [
        "prompt = \"To be, or not to be \"\n",
        "input_ids = torch.tensor([tokenizer.encode(prompt).ids], dtype=torch.long, device=device)\n",
        "out = model.generate(idx=input_ids, max_new_tokens=150)\n",
        "print(tokenizer.decode(out[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b366fe",
      "metadata": {},
      "source": [
        "### Test Another Model\n",
        "I trained the model with better parameters and for longer, and saved it for you. You can download my trained model and test it again below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece3a85c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n",
            "Vocab size: 20000\n",
            " To be, or not to be \n",
            "When he shall second grief, I say, if he lose it,\n",
            "After my interlude, and he hath VI meritorious\n",
            "Andadua frompeer his offence._\n",
            "\n",
            "KENT.\n",
            "These are you to putrif lieutenant;\n",
            "Horatio, my lord, I think we’ll after him.\n",
            "Give me avaunt tomorrow morning.\n",
            "\n",
            "GLOUCESTER.\n",
            "Get thee; I’ll to horse.\n",
            " Vernon; go not brown banquet. I’ll leave you betteroh\n",
            "Than now IbrePit, and griefs! And therefore still;\n",
            "I hear two Capulets, here there is troubled-avish shoot;\n",
            "For then I’ll abide wert a tick and murder with tenor.\n",
            "\n",
            "EDGAR.\n",
            "Fair coz? Men may\n"
          ]
        }
      ],
      "source": [
        "model_url = \"https://www.coreunitrdm.biozentrum.uni-wuerzburg.de/public.php/dav/files/G9NdHrd9F8wH39r/?accept=zip\"\n",
        "response = requests.get(model_url)\n",
        "model_pth = 'model.pth'\n",
        "with open(model_pth, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "model = BigramLanguageModel(20000, 256, 256, 8, 0.1, 8, device)\n",
        "model.load_state_dict(torch.load(model_pth, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "encode,decode, tokenizer, vocab_size = tokenize(text, 20000)\n",
        "\n",
        "prompt = \"To be, or not to be \"\n",
        "input_ids = torch.tensor([tokenizer.encode(prompt).ids], dtype=torch.long, device=device)\n",
        "out = model.generate(idx=input_ids, max_new_tokens=150)\n",
        "print(tokenizer.decode(out[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77bc070c",
      "metadata": {
        "id": "77bc070c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ad08802d",
      "metadata": {
        "id": "ad08802d"
      },
      "source": [
        "---\n",
        "### Sources:\n",
        "[Introduction to Large Language Models](https://www.baeldung.com/cs/large-language-models)\n",
        "\n",
        "[Youtube video about writing a GPT from scratch](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2409s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e747ec88",
      "metadata": {
        "id": "e747ec88"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
