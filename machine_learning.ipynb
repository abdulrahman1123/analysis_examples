{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Machine Learning Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, recall_score,confusion_matrix\n",
    "\n",
    "def choose_model(model, c_type = 'best', plot_result = True):\n",
    "    \"\"\"\n",
    "    This function chooses a model from a set of models identified using LogisticRegressionCV\n",
    "    It can return the best model (model.C_) or the most parsimonious model, which is the model whose score is\n",
    "    within 1 standard error from the best score\n",
    "    :param model: logistic regression model with cross validation (LogisticRegressionCV)\n",
    "    :param c_type: type of C value to return,\n",
    "                   can be either 'best' for best model, or 'par' for the most parsimonious model\n",
    "    :param plot_result: whether to plot the reult and show the best model and parsimonious model on the same figure\n",
    "    :return: C value for the chosen model\n",
    "    \"\"\"\n",
    "    n_folds = model.coefs_paths_[1.0].shape[0]\n",
    "    c_vals = model.Cs_\n",
    "    best_c = model.C_\n",
    "\n",
    "    best_c_ind = np.where(np.abs(c_vals - model.C_) < 1e-10)[0][0]\n",
    "\n",
    "    included_vars = np.sum(model.coefs_paths_[1.0].mean(axis=0) != 0,  axis=1) - 1  # the -1 is make sure the intercept is not included\n",
    "    included_vars = included_vars[\n",
    "        [int(item) for item in np.linspace(0, len(included_vars) - 1, 30)]]  # Take only 30 samples from included_vars\n",
    "    scores = model.scores_[1.0].mean(axis=0)\n",
    "    scores_sem = model.scores_[1.0].std(axis=0) / np.sqrt(n_folds)\n",
    "\n",
    "    # Get 1 standard error of the mean (SEM) from the best accuracy,\n",
    "    # According to Friedman, Hastie, and Tibshirani (2010): since risk curves are estimated\n",
    "    # with errors, it is better to err on the side of parsimony\n",
    "    best_sem = scores_sem[best_c_ind]\n",
    "\n",
    "    # finds the last point where scores are within one SEM from best score\n",
    "    c1se_ind = np.where(scores[best_c_ind] - scores[0:best_c_ind] < best_sem)[0][0]\n",
    "    c1se = model.Cs_[c1se_ind]  # least acceptable score\n",
    "    if plot_result:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax3 = ax.twiny()\n",
    "        ax3.set_xticks(np.arange(0, len(included_vars) + 2), [''] + list(included_vars) + [''], font = 'Cambria', fontsize = 12)\n",
    "        ax3.tick_params(width=0, length = 0)\n",
    "        ax3.set_xlabel('Included Variables', font = \"Cambria\", fontsize = 18)\n",
    "        ax.axvline(x=np.log(best_c), color='grey', ls='-', lw=1, label='Best Score Model')\n",
    "        ax.axvline(x=np.log(c1se), color='grey', ls='-.', lw=1, label='Parsimonious Model')\n",
    "        ax.errorbar(np.log(model.Cs_), scores, scores_sem, fmt='o', linewidth=1,\n",
    "                    color='grey', mfc='royalblue', mec='none', capsize=4)\n",
    "        ax.legend()\n",
    "        x_axis_text = np.round(ax.get_xticks()[1:-1],1)\n",
    "        y_axis_text = np.round(ax.get_yticks()[1:-1],1)\n",
    "        ax.set_xticks(ticks =x_axis_text, labels =  x_axis_text,font = 'Cambria', fontsize = 12)\n",
    "        ax.set_yticks(ticks =y_axis_text, labels =  y_axis_text,font = 'Cambria', fontsize = 12)\n",
    "        ax.set_xlabel('log(C)',font = 'Cambria', fontsize = 18)\n",
    "        ax.set_ylabel('Accuracy',font = 'Cambria', fontsize = 18)\n",
    "\n",
    "    if c_type=='best':\n",
    "        return model.C_[0]\n",
    "    elif c_type == 'par':\n",
    "        return c1se\n",
    "    else:\n",
    "        raise Warning(\"c_type can only be set to 'best' or 'par'\")\n",
    "\n",
    "\n",
    "def model_performance(model,X_test,y_test):\n",
    "    \"\"\"\n",
    "    Print the coefficients and compute accuracy\n",
    "    :param model: the model to be tested\n",
    "    :return: print the coeffcieints and compute accuracy\n",
    "    \"\"\"\n",
    "    # let's have a look at the coefficients and see if anything was removed\n",
    "    print('Coefficients:')\n",
    "    coefs = [model.intercept_[0]] + list(model.coef_[0])\n",
    "    coefs = [str(np.round(item,3)) if item!=0 else \"-\" for item in coefs]\n",
    "    coef_names = ['intercept'] + list(data.columns[1:-1])\n",
    "    coefficients = pd.DataFrame(coefs, index=coef_names,columns=['value'])\n",
    "    print(coefficients)\n",
    "    print('\\n Scores:')\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    sens = tp / (tp + fn)\n",
    "    spec = tn / (tn + fp)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(pd.DataFrame([[sens, spec, accuracy]], columns=['Sensitivity', 'Specificity', 'Accuracy']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data, impute missing values and have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>thickness</th>\n",
       "      <th>cell_size</th>\n",
       "      <th>cell_shape</th>\n",
       "      <th>adhesion</th>\n",
       "      <th>epithelial_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_cromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1184840.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.787671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1185609.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1185610.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1187457.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1187805.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  thickness  cell_size  cell_shape  adhesion  epithelial_size  \\\n",
       "0    1000025.0        5.0        1.0         1.0       1.0              2.0   \n",
       "1    1002945.0        5.0        4.0         4.0       5.0              7.0   \n",
       "2    1015425.0        3.0        1.0         1.0       1.0              2.0   \n",
       "3    1016277.0        6.0        8.0         8.0       1.0              3.0   \n",
       "4    1017023.0        4.0        1.0         1.0       3.0              2.0   \n",
       "..         ...        ...        ...         ...       ...              ...   \n",
       "145  1184840.0        1.0        1.0         3.0       1.0              2.0   \n",
       "146  1185609.0        3.0        4.0         5.0       2.0              6.0   \n",
       "147  1185610.0        1.0        1.0         1.0       1.0              3.0   \n",
       "148  1187457.0        3.0        1.0         1.0       3.0              8.0   \n",
       "149  1187805.0        8.0        8.0         7.0       4.0             10.0   \n",
       "\n",
       "     bare_nuclei  bland_cromatin  normal_nucleoli  mitoses  class  \n",
       "0       1.000000             3.0              1.0      1.0    0.0  \n",
       "1      10.000000             3.0              2.0      1.0    0.0  \n",
       "2       2.000000             3.0              1.0      1.0    0.0  \n",
       "3       4.000000             3.0              7.0      1.0    0.0  \n",
       "4       1.000000             3.0              1.0      1.0    0.0  \n",
       "..           ...             ...              ...      ...    ...  \n",
       "145     3.787671             2.0              1.0      1.0    0.0  \n",
       "146     8.000000             4.0              1.0      1.0    1.0  \n",
       "147     2.000000             2.0              1.0      1.0    0.0  \n",
       "148     1.000000             5.0              8.0      1.0    0.0  \n",
       "149    10.000000             7.0              8.0      7.0    1.0  \n",
       "\n",
       "[150 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = r'\\\\klinik.uni-wuerzburg.de\\homedir\\userdata11\\Sawalma_A\\data\\Documents\\12874_2019_681_MOESM1_ESM.csv'\n",
    "data = pd.read_csv(data_dir)\n",
    "data = data.iloc[0:150,:]\n",
    "\n",
    "# impute missing values\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_data = imp.fit_transform(data.copy())\n",
    "\n",
    "imp_data = pd.DataFrame(imp_data, columns=data.columns)\n",
    "imp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose features\n",
    "X = imp_data.iloc[:,1:-1]\n",
    "y = imp_data.iloc[:,-1]\n",
    "\n",
    "# Divide into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "# scale both X_train and X_test for faster convergence\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a number of c-values for the model to test. The model will \n",
    "\n",
    "Here is a representation from [scikit-learn website](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=440 height=305 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a number of c-values for the model to test.\n",
    "c_vals = np.logspace(-3,1, 50) # The smaller the value, the higher the penalty is\n",
    "\n",
    "\n",
    "cv_model = LogisticRegressionCV(Cs=c_vals,penalty='l1', cv=10,\n",
    "                             tol=0.001, solver='saga', scoring='accuracy')\n",
    "# you can also choose scoring = 'neg_mean_squared_error', but remember to multiply scores with -1\n",
    "\n",
    "# fit the model to the training data set\n",
    "cv_model.fit(X_train,y_train)\n",
    "\n",
    "# choose best model\n",
    "best_c = choose_model(model = cv_model,c_type='best', plot_result=True)\n",
    "best_model = LogisticRegression(C=best_c, penalty='l1', tol = 0.001, solver = 'saga').fit(X_train,y_train)\n",
    "model_performance(best_model,  X_test, y_test)\n",
    "\n",
    "# Choose parsimonious model\n",
    "par_c = choose_model(model = cv_model,c_type='par', plot_result=False)\n",
    "par_model = LogisticRegression(C=par_c, penalty='l1', tol = 0.001, solver = 'saga').fit(X_train,y_train)\n",
    "model_performance(par_model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
