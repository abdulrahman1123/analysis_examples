{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning and Neural Networks\n",
    "Deep Learning is a subset of machine learning algorithms. It is based on neural networks and is capable of learning complex patterns within the data. It's advantage over simple machine learning methods lies in the fact that it can be built by stacking a number of layers of neurons to discover heirarchical patterns of featurese within the data. Thus, it should be able to extract more complex features not otherwise detected by simpler machine learning algorithms\n",
    "\n",
    "<img src=\"https://developer.ibm.com/developer/default/articles/an-introduction-to-deep-learning/images/AI-ML-DL.png\" width=240 height=240 />\n",
    "\n",
    "Image source: [IBM Developer](https://developer.ibm.com/articles/an-introduction-to-deep-learning/)\n",
    "\n",
    "## Neural Networks\n",
    "The name \"Neural Networks\" comes from the structure of neurons in our brains, where multiple neurons connect to each other in layers to perform their respective functions. Although the similarity is vague, the name still catches on. To underestand this concept, let's start with explaining what is a neuron.\n",
    "\n",
    "#### The Neuron\n",
    "The basic building block of neural network is the neuron (sometimes called perceptron). It can be thought of as simple functions that take inputs and convert them to outputs. This conversion function is known as the activation function. In each neuron, the following steps take place:\n",
    "\n",
    "* Take the from each variable in the input layer and multiply it by a factor (weight)\n",
    "* Sum the product of inputs and weights and add a bias term (b)\n",
    "* Apply a function (activation function) to the final sum\n",
    "\n",
    "For the sake of understanding how a neuron works, let's assume we have a data for predicting the metastasis of a primary hepatic tumor. We collected four variables to be used for our task. These are the alpha fetoprotein (AFP), number of risk genes, alanine aminotransferase (ALT) and albumin level. The outcome for each patient is determined by an oncologist and is given in the column \"Met.\". The figure below shows how to use the input variables (coded $X_1$ to $X_4$) to compute the predicted output using one neuron. Each variable is multiplied by a particular weight, and the product of these multiplications are summed. A bias term is added at the end. Then, an activation function is used to convert the inputs to outpus (here, I used sigmoid function, but any other activation function should work).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/abdulrahman1123/analysis_examples/main/dl_neuron.png\" width=800 height=256 />\n",
    "\n",
    "#### Activation functions\n",
    "There is a number of activation functions that are commonly used. These include the sigmoid function and rectified linear unit (ReLU) function. Other activation functions include the the sigmoid function, tanh function, leaky ReLU function, step function and others. For further information, please refer to [THIS WEBSITE](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6).\n",
    "\n",
    "Sigmoid function is an S-shaped function that gives results between 0 and 1, and thus it is most appropriate when the outcome is binary. The ReLU function is a function that gives 0 for $x < 0$, and returns x when $x > 0$\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/abdulrahman1123/analysis_examples/main/dl_activations.png\" width=500 height=170 />\n",
    "\n",
    "#### Building Neural Networks\n",
    "The most basic form of neural networks consists of three layers: the input layer, a hidden layer and an output layer. In the hidden layer, neurons are arranged so that they receive input from the input layer and apply their activation functions on the input. The results are then passed to the output layer to give the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Further reading:\n",
    "[IBM Developer website](https://developer.ibm.com/articles/an-introduction-to-deep-learning/)\n",
    "\n",
    "[Activation Functions in Neural Networks](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)\n",
    "\n",
    "[Introduction to Deep Learning](https://www.geeksforgeeks.org/introduction-deep-learning/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
